{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d86b2774",
   "metadata": {},
   "source": [
    "Step 1: select small dataset from largedataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f48925",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your original dataset\n",
    "df = pd.read_csv(\"Credit Card Fraud Risk Analysis.csv\")\n",
    "\n",
    "# Take only first 1000 rows\n",
    "df_small = df.head(1000)\n",
    "\n",
    "# Save it as a new file\n",
    "df_small.to_csv(\"small_dataset.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4318aaa7",
   "metadata": {},
   "source": [
    "Step 2: show overview of small dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7c3041",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv(\"small_dataset.csv\")\n",
    "\n",
    "# Basic shape of the data\n",
    "print(\"üßæ Dataset Shape:\", df.shape)\n",
    "\n",
    "# First 5 rows\n",
    "print(\"\\nüîç First 5 Rows:\")\n",
    "display(df.head())\n",
    "\n",
    "# Info about columns and data types\n",
    "print(\"\\n‚ÑπÔ∏è Dataset Info:\")\n",
    "df.info()\n",
    "\n",
    "# Summary statistics for numeric columns\n",
    "print(\"\\nüìä Summary Statistics:\")\n",
    "display(df.describe())\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\n‚ùó Missing Values in Each Column:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Check for duplicate rows\n",
    "print(\"\\nüìã Number of Duplicate Rows:\", df.duplicated().sum())\n",
    "\n",
    "# Display column names\n",
    "print(\"\\nü™∂ Column Names:\")\n",
    "print(df.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4020a7",
   "metadata": {},
   "source": [
    "Step 3: Data Cleaning & Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22af574f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training shape: (800, 8)\n",
      "Testing shape: (200, 8)\n",
      "\n",
      "‚úÖ Preprocessing Complete. Sample:\n",
      "   Transaction Amount (INR)  Fraud Risk  Fraud Type     State  Card Type  \\\n",
      "0                 -0.749992   -0.930734    1.499900  1.553043   0.429265   \n",
      "1                 -0.744501   -0.930734    0.042271  0.495352  -1.337258   \n",
      "2                  0.543772    0.118571   -0.686543  0.495352  -0.453996   \n",
      "3                  1.606914    1.167877    1.499900 -1.620030  -0.453996   \n",
      "4                  1.560593    1.167877   -0.686543 -1.267467   0.429265   \n",
      "\n",
      "       Bank  Fraud Score  Transaction Category  \n",
      "0  0.752030     1.471007             -1.453254  \n",
      "1  1.135328    -0.084750             -0.293897  \n",
      "2 -0.781161    -1.329356              0.285781  \n",
      "3 -1.547756    -0.123644             -0.873575  \n",
      "4 -1.547756     0.148614             -0.293897  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "# Step 1: Load dataset\n",
    "df = pd.read_csv(\"small_dataset.csv\")\n",
    "\n",
    "# Step 2: Drop unnecessary columns\n",
    "# These are mostly identifiers or text not useful for ML\n",
    "df = df.drop(columns=[\n",
    "    \"Transaction ID\", \n",
    "    \"Customer Name\", \n",
    "    \"Merchant Name\", \n",
    "    \"Transaction Date\", \n",
    "    \"Merchant Location\"\n",
    "])\n",
    "\n",
    "# Step 3: Encode categorical columns\n",
    "label_encoder = LabelEncoder()\n",
    "categorical_cols = df.select_dtypes(include=[\"object\"]).columns\n",
    "\n",
    "for col in categorical_cols:\n",
    "    df[col] = label_encoder.fit_transform(df[col])\n",
    "\n",
    "# Step 4: Separate features and target\n",
    "X = df.drop(columns=[\"IsFraud\"])\n",
    "y = df[\"IsFraud\"]\n",
    "\n",
    "# Step 5: Scale numerical features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Step 6: Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Step 7: Print shapes to verify\n",
    "print(\"Training shape:\", X_train.shape)\n",
    "print(\"Testing shape:\", X_test.shape)\n",
    "\n",
    "# Step 8: Show processed sample\n",
    "print(\"\\n‚úÖ Preprocessing Complete. Sample:\")\n",
    "print(pd.DataFrame(X_train, columns=X.columns).head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb28efe",
   "metadata": {},
   "source": [
    "Step 4: Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6385cc33",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.head())\n",
    "print(df.shape)\n",
    "print(df['is_Fraud'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297fec6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Model Training Complete\n",
      "\n",
      "Accuracy: 0.715 (71.50%)\n",
      "\n",
      "üìä Confusion Matrix:\n",
      "[[143   0]\n",
      " [ 57   0]]\n",
      "\n",
      "üìã Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      1.00      0.83       143\n",
      "           1       0.00      0.00      0.00        57\n",
      "\n",
      "    accuracy                           0.71       200\n",
      "   macro avg       0.36      0.50      0.42       200\n",
      "weighted avg       0.51      0.71      0.60       200\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zain Latif\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\Zain Latif\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\Zain Latif\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# STEP 4: MODEL TRAINING\n",
    "# =========================\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Initialize and train model\n",
    "model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"‚úÖ Model Training Complete\\n\")\n",
    "print(f\"Accuracy: {accuracy:.3f} ({accuracy*100:.2f}%)\\n\")\n",
    "print(\"üìä Confusion Matrix:\")\n",
    "print(cm)\n",
    "print(\"\\nüìã Classification Report:\")\n",
    "print(report)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
